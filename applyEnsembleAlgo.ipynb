{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shill Bidding Dataset Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import where\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pandas import Series, DataFrame\n",
    "from scipy import stats\n",
    "#from scipy.special import boxcox1p\n",
    "#from scipy.stats import boxcox_normmax\n",
    "from sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\n",
    "#from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#Common Model Helpers\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn import feature_selection\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import random\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "#Visualization\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib import pyplot\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import optuna\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from sklearn.svm import SVC\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.2\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Record_ID</th>\n",
       "      <th>Auction_ID</th>\n",
       "      <th>Bidder_ID</th>\n",
       "      <th>Bidder_Tendency</th>\n",
       "      <th>Bidding_Ratio</th>\n",
       "      <th>Successive_Outbidding</th>\n",
       "      <th>Last_Bidding</th>\n",
       "      <th>Auction_Bids</th>\n",
       "      <th>Starting_Price_Average</th>\n",
       "      <th>Early_Bidding</th>\n",
       "      <th>Winning_Ratio</th>\n",
       "      <th>Auction_Duration</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>732</td>\n",
       "      <td>_***i</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.993593</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>732</td>\n",
       "      <td>g***r</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013123</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.993593</td>\n",
       "      <td>0.013123</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>732</td>\n",
       "      <td>t***p</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003042</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.993593</td>\n",
       "      <td>0.003042</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>732</td>\n",
       "      <td>7***n</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.097477</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.993593</td>\n",
       "      <td>0.097477</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>900</td>\n",
       "      <td>z***z</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001318</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001242</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Record_ID  Auction_ID Bidder_ID  Bidder_Tendency  Bidding_Ratio  \\\n",
       "0          1         732     _***i         0.200000       0.400000   \n",
       "1          2         732     g***r         0.024390       0.200000   \n",
       "2          3         732     t***p         0.142857       0.200000   \n",
       "3          4         732     7***n         0.100000       0.200000   \n",
       "4          5         900     z***z         0.051282       0.222222   \n",
       "\n",
       "   Successive_Outbidding  Last_Bidding  Auction_Bids  Starting_Price_Average  \\\n",
       "0                    0.0      0.000028           0.0                0.993593   \n",
       "1                    0.0      0.013123           0.0                0.993593   \n",
       "2                    0.0      0.003042           0.0                0.993593   \n",
       "3                    0.0      0.097477           0.0                0.993593   \n",
       "4                    0.0      0.001318           0.0                0.000000   \n",
       "\n",
       "   Early_Bidding  Winning_Ratio  Auction_Duration  Class  \n",
       "0       0.000028       0.666667                 5      0  \n",
       "1       0.013123       0.944444                 5      0  \n",
       "2       0.003042       1.000000                 5      0  \n",
       "3       0.097477       1.000000                 5      0  \n",
       "4       0.001242       0.500000                 7      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shill = pd.read_csv('Shill_Bidding_Dataset.csv')\n",
    "shill.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bidder_Tendency</th>\n",
       "      <th>Bidding_Ratio</th>\n",
       "      <th>Successive_Outbidding</th>\n",
       "      <th>Last_Bidding</th>\n",
       "      <th>Auction_Bids</th>\n",
       "      <th>Starting_Price_Average</th>\n",
       "      <th>Early_Bidding</th>\n",
       "      <th>Winning_Ratio</th>\n",
       "      <th>Auction_Duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.993593</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013123</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.993593</td>\n",
       "      <td>0.013123</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003042</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.993593</td>\n",
       "      <td>0.003042</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.097477</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.993593</td>\n",
       "      <td>0.097477</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.051282</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001318</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001242</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6316</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.738557</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.993593</td>\n",
       "      <td>0.686358</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6317</th>\n",
       "      <td>0.030612</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005754</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.993593</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6318</th>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015663</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.993593</td>\n",
       "      <td>0.015663</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6319</th>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.068694</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.993593</td>\n",
       "      <td>0.000415</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6320</th>\n",
       "      <td>0.016393</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.340351</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.993593</td>\n",
       "      <td>0.340351</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6321 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Bidder_Tendency  Bidding_Ratio  Successive_Outbidding  Last_Bidding  \\\n",
       "0            0.200000       0.400000                    0.0      0.000028   \n",
       "1            0.024390       0.200000                    0.0      0.013123   \n",
       "2            0.142857       0.200000                    0.0      0.003042   \n",
       "3            0.100000       0.200000                    0.0      0.097477   \n",
       "4            0.051282       0.222222                    0.0      0.001318   \n",
       "...               ...            ...                    ...           ...   \n",
       "6316         0.333333       0.160000                    1.0      0.738557   \n",
       "6317         0.030612       0.130435                    0.0      0.005754   \n",
       "6318         0.055556       0.043478                    0.0      0.015663   \n",
       "6319         0.076923       0.086957                    0.0      0.068694   \n",
       "6320         0.016393       0.043478                    0.0      0.340351   \n",
       "\n",
       "      Auction_Bids  Starting_Price_Average  Early_Bidding  Winning_Ratio  \\\n",
       "0         0.000000                0.993593       0.000028       0.666667   \n",
       "1         0.000000                0.993593       0.013123       0.944444   \n",
       "2         0.000000                0.993593       0.003042       1.000000   \n",
       "3         0.000000                0.993593       0.097477       1.000000   \n",
       "4         0.000000                0.000000       0.001242       0.500000   \n",
       "...            ...                     ...            ...            ...   \n",
       "6316      0.280000                0.993593       0.686358       0.888889   \n",
       "6317      0.217391                0.993593       0.000010       0.878788   \n",
       "6318      0.217391                0.993593       0.015663       0.000000   \n",
       "6319      0.217391                0.993593       0.000415       0.000000   \n",
       "6320      0.217391                0.993593       0.340351       0.000000   \n",
       "\n",
       "      Auction_Duration  \n",
       "0                    5  \n",
       "1                    5  \n",
       "2                    5  \n",
       "3                    5  \n",
       "4                    7  \n",
       "...                ...  \n",
       "6316                 3  \n",
       "6317                 7  \n",
       "6318                 7  \n",
       "6319                 7  \n",
       "6320                 7  \n",
       "\n",
       "[6321 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = shill.drop(columns=['Class', 'Record_ID', 'Auction_ID', 'Bidder_ID'])\n",
    "y = shill.Class\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5646\n",
       "1     675\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 4044\n",
      "Validation set: 1012\n",
      "Test set: 1265\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, stratify = y, random_state = seed)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.2, stratify = y_train, random_state = seed)\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]}\")\n",
    "print(f\"Validation set: {X_val.shape[0]}\")\n",
    "print(f\"Test set: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class balance by Undersampling\n",
    "\n",
    "When undersampling, we aim to remove a number of the rows of the majority class (rows where class=0) in order to match the number of rows of the minority class (rows where class=1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3612\n",
       "1     432\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler(random_state=seed)\n",
    "X_train_us_ini, y_train_us_ini = rus.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    432\n",
       "1    432\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_us_ini.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_us, X_val_us, y_train_us, y_val_us = train_test_split(X_train_us_ini, y_train_us_ini, test_size=0.2, random_state = seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class balance by oversampling with SMOTE\n",
    "\n",
    "Now, oversampling will be performed on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3612\n",
       "1     432\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3612\n",
       "1    3612\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smote = SMOTE(random_state=seed)\n",
    "\n",
    "X_train_os_ini, y_train_os_ini = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "y_train_os_ini.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_os, X_val_os, y_train_os, y_val_os = train_test_split(X_train_os_ini, y_train_os_ini, stratify=y_train_os_ini, test_size=0.2, random_state = seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid Sampling Method\n",
    "\n",
    "A combination of under- and oversampling method using pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 675, 1: 675})\n"
     ]
    }
   ],
   "source": [
    "# define pipeline\n",
    "over = SMOTE(sampling_strategy = \"not minority\")\n",
    "under = RandomUnderSampler(sampling_strategy = \"majority\")\n",
    "steps = [('o', over), ('u', under)]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "\n",
    "# transform the dataset\n",
    "X_h, y_h = pipeline.fit_resample(X, y)\n",
    "# summarize the new class distribution\n",
    "counter = Counter(y_h)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 864\n",
      "Validation set: 216\n",
      "Test set: 270\n"
     ]
    }
   ],
   "source": [
    "X_train_h, X_test_h, y_train_h, y_test_h = train_test_split(X_h, y_h, test_size=0.2, stratify = y_h, random_state=seed)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_h = scaler.fit_transform(X_train_h)\n",
    "X_test_h = scaler.transform(X_test_h)\n",
    "\n",
    "X_train_h, X_val_h, y_train_h, y_val_h = train_test_split(X_train_h, y_train_h, test_size=0.2, stratify=y_train_h, random_state=seed)\n",
    "\n",
    "print(f\"Training set: {X_train_h.shape[0]}\")\n",
    "print(f\"Validation set: {X_val_h.shape[0]}\")\n",
    "print(f\"Test set: {X_test_h.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying Ensemble Learning Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensemble Algorithms\n",
    "\n",
    "    1. Bagged Decision Trees\n",
    "    2. Extra Trees\n",
    "    3. Stochastic Gradient Boosting\n",
    "    4. AdaBoost\n",
    "    5. XGBoost\n",
    "    6. Gradient Boosting\n",
    "    \n",
    "Hyperparameter Tuning\n",
    "After spot-checking machine learning algorithms and imbalanced algorithms, you will have some idea of what works and what does not on your specific dataset.\n",
    "\n",
    "The simplest approach to hyperparameter tuning is to select the top five or 10 algorithms or algorithm combinations that performed well and tune the hyperparameters for each.\n",
    "\n",
    "There are three popular hyperparameter tuning algorithms that you may choose from:\n",
    "\n",
    "    Random Search\n",
    "    Grid Search\n",
    "    Bayesian Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagged Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kfold = KFold(n_splits = 10, random_state = seed)\n",
    "# cart = DecisionTreeClassifier()\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# kfold = model_selection.KFold(n_splits=10, random_state=42)\n",
    "# bclf = BaggingClassifier(base_estimator = cart, n_estimators = 200, random_state = seed)\n",
    "\n",
    "# scoring = ['accuracy', 'precision', 'recall', 'f1']\n",
    "\n",
    "# results = model_selection.cross_validate(bclf, X_scaled, y, cv = kfold, scoring = scoring)\n",
    "\n",
    "# for name in results.keys():\n",
    "#      print('{} {:.6f}'.format(name, np.average(results[name])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cart = DecisionTreeClassifier()\n",
    "scaler = StandardScaler()\n",
    "\n",
    "\n",
    "bclf = BaggingClassifier(base_estimator = cart, random_state = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'base_estimator__ccp_alpha': 0.0,\n",
       " 'base_estimator__class_weight': None,\n",
       " 'base_estimator__criterion': 'gini',\n",
       " 'base_estimator__max_depth': None,\n",
       " 'base_estimator__max_features': None,\n",
       " 'base_estimator__max_leaf_nodes': None,\n",
       " 'base_estimator__min_impurity_decrease': 0.0,\n",
       " 'base_estimator__min_samples_leaf': 1,\n",
       " 'base_estimator__min_samples_split': 2,\n",
       " 'base_estimator__min_weight_fraction_leaf': 0.0,\n",
       " 'base_estimator__random_state': None,\n",
       " 'base_estimator__splitter': 'best',\n",
       " 'base_estimator': DecisionTreeClassifier(),\n",
       " 'bootstrap': True,\n",
       " 'bootstrap_features': False,\n",
       " 'max_features': 1.0,\n",
       " 'max_samples': 1.0,\n",
       " 'n_estimators': 10,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': 42,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "\n",
    "bclf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=DecisionTreeClassifier(), max_features=0.9,\n",
       "                  max_samples=0.5, n_estimators=16, random_state=42)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'max_samples': [0.05, 0.1, 0.2, 0.5],\n",
    "              'max_features': [0.3,0.5,0.7,0.9],\n",
    "             }\n",
    "\n",
    "\n",
    "sh = HalvingGridSearchCV(bclf, param_grid, cv = 10,\n",
    "                         factor=2, resource = 'n_estimators',\n",
    "                         max_resources=30).fit(X_train, y_train)\n",
    "sh.best_estimator_\n",
    "# bclf = BaggingClassifier(base_estimator = cart, n_estimators = 402, max_samples = 0.08, max_features = 0.06, random_state = seed).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No   0.998230  0.998230  0.998230      1130\n",
      "         Yes   0.985185  0.985185  0.985185       135\n",
      "\n",
      "    accuracy                       0.996838      1265\n",
      "   macro avg   0.991708  0.991708  0.991708      1265\n",
      "weighted avg   0.996838  0.996838  0.996838      1265\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bclf = BaggingClassifier(base_estimator = DecisionTreeClassifier(), n_estimators = 16, max_samples = 0.5, max_features = 0.9, random_state = seed).fit(X_train, y_train)\n",
    "y_pred = bclf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names = ['No','Yes'], digits = 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undersampled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "bclf = BaggingClassifier(base_estimator = cart, random_state = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=DecisionTreeClassifier(), max_features=0.9,\n",
       "                  max_samples=0.5, n_estimators=16, random_state=42)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hyperparameter tuning\n",
    "param_grid = {'max_samples': [0.05, 0.1, 0.2, 0.5],\n",
    "              'max_features': [0.3,0.5,0.7,0.9],\n",
    "             }\n",
    "\n",
    "\n",
    "sh = HalvingGridSearchCV(bclf, param_grid, cv = 10,\n",
    "                         factor=2, resource = 'n_estimators',\n",
    "                         max_resources=30).fit(X_train_us, y_train_us)\n",
    "sh.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No   1.000000  0.981416  0.990621      1130\n",
      "         Yes   0.865385  1.000000  0.927835       135\n",
      "\n",
      "    accuracy                       0.983399      1265\n",
      "   macro avg   0.932692  0.990708  0.959228      1265\n",
      "weighted avg   0.985634  0.983399  0.983920      1265\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bclf = BaggingClassifier(base_estimator = DecisionTreeClassifier(), n_estimators = 16, max_samples = 0.5, max_features = 0.9, random_state = seed).fit(X_train_us, y_train_us)\n",
    "y_pred = bclf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names = ['No','Yes'], digits = 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversampled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "bclf = BaggingClassifier(base_estimator = cart, random_state = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=DecisionTreeClassifier(), max_features=0.9,\n",
       "                  max_samples=0.5, n_estimators=16, random_state=42)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hyperparameter tuning\n",
    "param_grid = {'max_samples': [0.05, 0.1, 0.2, 0.5],\n",
    "              'max_features': [0.3,0.5,0.7,0.9],\n",
    "             }\n",
    "\n",
    "\n",
    "sh = HalvingGridSearchCV(bclf, param_grid, cv = 10,\n",
    "                         factor=2, resource = 'n_estimators',\n",
    "                         max_resources=30).fit(X_train_os, y_train_os)\n",
    "sh.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No   0.999114  0.998230  0.998672      1130\n",
      "         Yes   0.985294  0.992593  0.988930       135\n",
      "\n",
      "    accuracy                       0.997628      1265\n",
      "   macro avg   0.992204  0.995411  0.993801      1265\n",
      "weighted avg   0.997639  0.997628  0.997632      1265\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bclf = BaggingClassifier(base_estimator = DecisionTreeClassifier(), n_estimators = 16, max_samples = 0.5, max_features = 0.9, random_state = seed).fit(X_train_os, y_train_os)\n",
    "y_pred = bclf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names = ['No','Yes'], digits = 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hybrid Sampled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "bclf = BaggingClassifier(base_estimator = cart, n_estimators = 150, random_state = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 0.9, 'max_samples': 0.2, 'n_estimators': 16}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hyperparameter tuning\n",
    "param_grid = {'max_samples': [0.05, 0.1, 0.2, 0.5],\n",
    "              'max_features': [0.3,0.5,0.7,0.9],\n",
    "             }\n",
    "\n",
    "\n",
    "sh = HalvingGridSearchCV(bclf, param_grid, cv = 10,\n",
    "                         factor=2, resource = 'n_estimators',\n",
    "                         max_resources=30).fit(X_train_h, y_train_h)\n",
    "sh.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No   1.000000  0.330088  0.496341      1130\n",
      "         Yes   0.151345  1.000000  0.262902       135\n",
      "\n",
      "    accuracy                       0.401581      1265\n",
      "   macro avg   0.575673  0.665044  0.379621      1265\n",
      "weighted avg   0.909432  0.401581  0.471428      1265\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bclf = BaggingClassifier(base_estimator = DecisionTreeClassifier(), n_estimators = 16, max_samples = 0.5, max_features = 0.9, random_state = seed).fit(X_train_h, y_train_h)\n",
    "\n",
    "y_pred = bclf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names = ['No','Yes'], digits = 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Trees Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imbalanced Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': False,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 5,\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 150,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "xtclf = ExtraTreesClassifier(n_estimators = 150, max_features = 5)\n",
    "xtclf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(max_features=0.9, n_estimators=28)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hyperparameter tuning\n",
    "param_grid = {#'max_depth': [0.05, 0.1, 0.2, 0.5],\n",
    "              'max_features': [0.3,0.5,0.7,0.9],\n",
    "              #'n_jobs': [20, 60, 80, 120]\n",
    "             }\n",
    "\n",
    "\n",
    "sh = HalvingGridSearchCV(xtclf, param_grid, cv = 10,\n",
    "                         factor=2, resource = 'n_estimators',\n",
    "                         max_resources=30).fit(X_train, y_train)\n",
    "sh.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No   0.997352  1.000000  0.998674      1130\n",
      "         Yes   1.000000  0.977778  0.988764       135\n",
      "\n",
      "    accuracy                       0.997628      1265\n",
      "   macro avg   0.998676  0.988889  0.993719      1265\n",
      "weighted avg   0.997635  0.997628  0.997617      1265\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xtclf = ExtraTreesClassifier(n_estimators = 28, max_features = 0.9).fit(X_train, y_train)\n",
    "\n",
    "y_pred = xtclf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names = ['No','Yes'], digits = 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undersampled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtclf = ExtraTreesClassifier(n_estimators = 150, max_features = 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(max_features=0.7, n_estimators=28)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hyperparameter tuning\n",
    "param_grid = {#'max_depth': [0.05, 0.1, 0.2, 0.5],\n",
    "              'max_features': [0.3,0.5,0.7,0.9],\n",
    "              #'n_jobs': [20, 60, 80, 120]\n",
    "             }\n",
    "\n",
    "\n",
    "sh = HalvingGridSearchCV(xtclf, param_grid, cv = 10,\n",
    "                         factor=2, resource = 'n_estimators',\n",
    "                         max_resources=30).fit(X_train_us, y_train_us)\n",
    "sh.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No   1.000000  0.983186  0.991522      1130\n",
      "         Yes   0.876623  1.000000  0.934256       135\n",
      "\n",
      "    accuracy                       0.984980      1265\n",
      "   macro avg   0.938312  0.991593  0.962889      1265\n",
      "weighted avg   0.986833  0.984980  0.985410      1265\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xtclf = ExtraTreesClassifier(n_estimators = 28, max_features = 0.7).fit(X_train_us, y_train_us)\n",
    "\n",
    "y_pred = xtclf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names = ['No','Yes'], digits = 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversampled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtclf = ExtraTreesClassifier(n_estimators = 150, max_features = 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(max_features=0.9, n_estimators=28)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hyperparameter tuning\n",
    "param_grid = {#'max_depth': [0.05, 0.1, 0.2, 0.5],\n",
    "              'max_features': [0.3,0.5,0.7,0.9],\n",
    "              #'n_jobs': [20, 60, 80, 120]\n",
    "             }\n",
    "\n",
    "\n",
    "sh = HalvingGridSearchCV(xtclf, param_grid, cv = 10,\n",
    "                         factor=2, resource = 'n_estimators',\n",
    "                         max_resources=30).fit(X_train_os, y_train_os)\n",
    "sh.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No   0.996473  1.000000  0.998233      1130\n",
      "         Yes   1.000000  0.970370  0.984962       135\n",
      "\n",
      "    accuracy                       0.996838      1265\n",
      "   macro avg   0.998236  0.985185  0.991598      1265\n",
      "weighted avg   0.996849  0.996838  0.996817      1265\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xtclf = ExtraTreesClassifier(n_estimators = 28, max_features = 0.9).fit(X_train_os, y_train_os)\n",
    "\n",
    "y_pred = xtclf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names = ['No','Yes'], digits = 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hybrid Sampled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No   1.000000  0.810619  0.895406      1130\n",
      "         Yes   0.386819  1.000000  0.557851       135\n",
      "\n",
      "    accuracy                       0.830830      1265\n",
      "   macro avg   0.693410  0.905310  0.726628      1265\n",
      "weighted avg   0.934562  0.830830  0.859382      1265\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xtclf = ExtraTreesClassifier(n_estimators = 150, max_features = 5).fit(X_train_h, y_train_h)\n",
    "y_pred = xtclf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names = ['No','Yes'], digits = 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imbalanced Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "# kfold = KFold(n_splits = 10, random_state = seed)\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# kfold = model_selection.KFold(n_splits=10, random_state=42)\n",
    "\n",
    "# gbclf = GradientBoostingClassifier(n_estimators = 50, random_state=seed)\n",
    "\n",
    "# scoring = ['accuracy', 'precision', 'recall', 'f1']\n",
    "\n",
    "# results = model_selection.cross_validate(gbclf, X_scaled, y, cv = kfold, scoring = scoring)\n",
    "\n",
    "# for name in results.keys():\n",
    "#      print('{} {:.6f}'.format(name, np.average(results[name])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No   0.998229  0.997345  0.997787      1130\n",
      "         Yes   0.977941  0.985185  0.981550       135\n",
      "\n",
      "    accuracy                       0.996047      1265\n",
      "   macro avg   0.988085  0.991265  0.989668      1265\n",
      "weighted avg   0.996063  0.996047  0.996054      1265\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gbclf = GradientBoostingClassifier(n_estimators = 50, random_state=seed).fit(X_train, y_train)\n",
    "\n",
    "y_pred = gbclf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names = ['No','Yes'], digits = 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 0, Score: 0.00314\n",
      "Feature: 1, Score: 0.00965\n",
      "Feature: 2, Score: 0.85907\n",
      "Feature: 3, Score: 0.00068\n",
      "Feature: 4, Score: 0.00013\n",
      "Feature: 5, Score: 0.00019\n",
      "Feature: 6, Score: 0.00038\n",
      "Feature: 7, Score: 0.05390\n",
      "Feature: 8, Score: 0.07285\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "importance = gbclf.feature_importances_\n",
    "\n",
    "# summarize feature importance\n",
    "for i,v in enumerate(importance):\n",
    "    print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "\n",
    "# plot feature importance\n",
    "pyplot.bar([x for x in range(len(importance))], importance)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undersampled Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No   0.999094  0.976106  0.987466      1130\n",
      "         Yes   0.832298  0.992593  0.905405       135\n",
      "\n",
      "    accuracy                       0.977866      1265\n",
      "   macro avg   0.915696  0.984349  0.946436      1265\n",
      "weighted avg   0.981294  0.977866  0.978709      1265\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gbclf = GradientBoostingClassifier(n_estimators = 50, random_state=seed).fit(X_train_us, y_train_us)\n",
    "\n",
    "y_pred = gbclf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names = ['No','Yes'], digits = 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversampled Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No   1.000000  0.991150  0.995556      1130\n",
      "         Yes   0.931034  1.000000  0.964286       135\n",
      "\n",
      "    accuracy                       0.992095      1265\n",
      "   macro avg   0.965517  0.995575  0.979921      1265\n",
      "weighted avg   0.992640  0.992095  0.992218      1265\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gbclf = GradientBoostingClassifier(n_estimators = 50, random_state=seed).fit(X_train_os, y_train_os)\n",
    "\n",
    "y_pred = gbclf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names = ['No','Yes'], digits = 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hybrid sampled Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No   1.000000  0.369027  0.539108      1130\n",
      "         Yes   0.159198  1.000000  0.274669       135\n",
      "\n",
      "    accuracy                       0.436364      1265\n",
      "   macro avg   0.579599  0.684513  0.406889      1265\n",
      "weighted avg   0.910270  0.436364  0.510887      1265\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gbclf = GradientBoostingClassifier(n_estimators = 50, random_state=seed).fit(X_train_h, y_train_h)\n",
    "\n",
    "y_pred = gbclf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names = ['No','Yes'], digits = 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imbalanced Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "# kfold = KFold(n_splits = 10, random_state = seed)\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# kfold = model_selection.KFold(n_splits = 10, random_state = 42)\n",
    "\n",
    "# abclf = AdaBoostClassifier(n_estimators = 50, random_state = seed)\n",
    "\n",
    "# scoring = ['accuracy', 'precision', 'recall', 'f1']\n",
    "\n",
    "# results = model_selection.cross_validate(abclf, X_scaled, y, cv = kfold, scoring = scoring)\n",
    "\n",
    "# for name in results.keys():\n",
    "#      print('{} {:.6f}'.format(name, np.average(results[name])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No   1.000000  0.995575  0.997783      1130\n",
      "         Yes   0.964286  1.000000  0.981818       135\n",
      "\n",
      "    accuracy                       0.996047      1265\n",
      "   macro avg   0.982143  0.997788  0.989800      1265\n",
      "weighted avg   0.996189  0.996047  0.996079      1265\n",
      "\n"
     ]
    }
   ],
   "source": [
    "abclf = AdaBoostClassifier(n_estimators = 50, random_state=seed).fit(X_train, y_train)\n",
    "\n",
    "y_pred = abclf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names = ['No','Yes'], digits = 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 0, Score: 0.06000\n",
      "Feature: 1, Score: 0.26000\n",
      "Feature: 2, Score: 0.12000\n",
      "Feature: 3, Score: 0.12000\n",
      "Feature: 4, Score: 0.04000\n",
      "Feature: 5, Score: 0.04000\n",
      "Feature: 6, Score: 0.06000\n",
      "Feature: 7, Score: 0.06000\n",
      "Feature: 8, Score: 0.24000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "importance = abclf.feature_importances_\n",
    "\n",
    "# summarize feature importance\n",
    "for i,v in enumerate(importance):\n",
    "    print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "\n",
    "# plot feature importance\n",
    "pyplot.bar([x for x in range(len(importance))], importance)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undersampled Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No   0.997300  0.980531  0.988844      1130\n",
      "         Yes   0.857143  0.977778  0.913495       135\n",
      "\n",
      "    accuracy                       0.980237      1265\n",
      "   macro avg   0.927221  0.979154  0.951170      1265\n",
      "weighted avg   0.982342  0.980237  0.980803      1265\n",
      "\n"
     ]
    }
   ],
   "source": [
    "abclf = AdaBoostClassifier(n_estimators = 50, random_state=seed).fit(X_train_us, y_train_us)\n",
    "\n",
    "y_pred = abclf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names = ['No','Yes'], digits = 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversampled Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No   0.999111  0.994690  0.996896      1130\n",
      "         Yes   0.957143  0.992593  0.974545       135\n",
      "\n",
      "    accuracy                       0.994466      1265\n",
      "   macro avg   0.978127  0.993641  0.985721      1265\n",
      "weighted avg   0.994632  0.994466  0.994511      1265\n",
      "\n"
     ]
    }
   ],
   "source": [
    "abclf = AdaBoostClassifier(n_estimators = 50, random_state=seed).fit(X_train_os, y_train_os)\n",
    "\n",
    "y_pred = abclf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names = ['No','Yes'], digits = 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hybrid sampled Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No   1.000000  0.508850  0.674487      1130\n",
      "         Yes   0.195652  1.000000  0.327273       135\n",
      "\n",
      "    accuracy                       0.561265      1265\n",
      "   macro avg   0.597826  0.754425  0.500880      1265\n",
      "weighted avg   0.914161  0.561265  0.637432      1265\n",
      "\n"
     ]
    }
   ],
   "source": [
    "abclf = AdaBoostClassifier(n_estimators = 50, random_state=seed).fit(X_train_h, y_train_h)\n",
    "\n",
    "y_pred = abclf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names = ['No','Yes'], digits = 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imbalanced Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "# kfold = KFold(n_splits = 10, random_state = seed)\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# kfold = model_selection.KFold(n_splits = 10, random_state = 42)\n",
    "\n",
    "# xgbclf = XGBClassifier(n_estimators = 50, random_state = seed)\n",
    "\n",
    "# scoring = ['accuracy', 'precision', 'recall', 'f1']\n",
    "\n",
    "# results = model_selection.cross_validate(xgbclf, X_scaled, y, cv = kfold, scoring = scoring)\n",
    "\n",
    "# for name in results.keys():\n",
    "#      print('{} {:.6f}'.format(name, np.average(results[name])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:37:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No   0.997343  0.996460  0.996901      1130\n",
      "         Yes   0.970588  0.977778  0.974170       135\n",
      "\n",
      "    accuracy                       0.994466      1265\n",
      "   macro avg   0.983966  0.987119  0.985536      1265\n",
      "weighted avg   0.994488  0.994466  0.994475      1265\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgbclf = XGBClassifier(n_estimators = 50, random_state=seed).fit(X_train, y_train)\n",
    "\n",
    "y_pred = xgbclf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names = ['No','Yes'], digits = 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 0, Score: 0.00695\n",
      "Feature: 1, Score: 0.00647\n",
      "Feature: 2, Score: 0.80607\n",
      "Feature: 3, Score: 0.01545\n",
      "Feature: 4, Score: 0.00358\n",
      "Feature: 5, Score: 0.00387\n",
      "Feature: 6, Score: 0.00512\n",
      "Feature: 7, Score: 0.08410\n",
      "Feature: 8, Score: 0.06839\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "importance = xgbclf.feature_importances_\n",
    "\n",
    "# summarize feature importance\n",
    "for i,v in enumerate(importance):\n",
    "    print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "\n",
    "# plot feature importance\n",
    "pyplot.bar([x for x in range(len(importance))], importance)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undersampled Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:37:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No   0.999100  0.982301  0.990629      1130\n",
      "         Yes   0.870130  0.992593  0.927336       135\n",
      "\n",
      "    accuracy                       0.983399      1265\n",
      "   macro avg   0.934615  0.987447  0.958982      1265\n",
      "weighted avg   0.985336  0.983399  0.983875      1265\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "xgbclf = XGBClassifier(n_estimators = 50, random_state=seed).fit(X_train_us, y_train_us)\n",
    "\n",
    "y_pred = xgbclf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names = ['No','Yes'], digits = 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversampled Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:37:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No   0.997340  0.995575  0.996457      1130\n",
      "         Yes   0.963504  0.977778  0.970588       135\n",
      "\n",
      "    accuracy                       0.993676      1265\n",
      "   macro avg   0.980422  0.986676  0.983523      1265\n",
      "weighted avg   0.993729  0.993676  0.993696      1265\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgbclf = XGBClassifier(n_estimators = 50, random_state=seed).fit(X_train_os, y_train_os)\n",
    "\n",
    "y_pred = xgbclf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names = ['No','Yes'], digits = 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hybrid Sampled Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:37:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No   1.000000  0.369027  0.539108      1130\n",
      "         Yes   0.159198  1.000000  0.274669       135\n",
      "\n",
      "    accuracy                       0.436364      1265\n",
      "   macro avg   0.579599  0.684513  0.406889      1265\n",
      "weighted avg   0.910270  0.436364  0.510887      1265\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "xgbclf = XGBClassifier(n_estimators = 50, random_state=seed).fit(X_train_h, y_train_h)\n",
    "\n",
    "y_pred = xgbclf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names = ['No','Yes'], digits = 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
