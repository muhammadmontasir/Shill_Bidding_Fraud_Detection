{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shill Bidding Dataset Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import where\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pandas import Series, DataFrame\n",
    "from scipy import stats\n",
    "#from scipy.special import boxcox1p\n",
    "#from scipy.stats import boxcox_normmax\n",
    "from sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\n",
    "#from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#Common Model Helpers\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn import feature_selection\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import random\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "#Visualization\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib import pyplot\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import optuna\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from sklearn.svm import SVC\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Record_ID</th>\n",
       "      <th>Auction_ID</th>\n",
       "      <th>Bidder_ID</th>\n",
       "      <th>Bidder_Tendency</th>\n",
       "      <th>Bidding_Ratio</th>\n",
       "      <th>Successive_Outbidding</th>\n",
       "      <th>Last_Bidding</th>\n",
       "      <th>Auction_Bids</th>\n",
       "      <th>Starting_Price_Average</th>\n",
       "      <th>Early_Bidding</th>\n",
       "      <th>Winning_Ratio</th>\n",
       "      <th>Auction_Duration</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>732</td>\n",
       "      <td>_***i</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.993593</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>732</td>\n",
       "      <td>g***r</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013123</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.993593</td>\n",
       "      <td>0.013123</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>732</td>\n",
       "      <td>t***p</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003042</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.993593</td>\n",
       "      <td>0.003042</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>732</td>\n",
       "      <td>7***n</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.097477</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.993593</td>\n",
       "      <td>0.097477</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>900</td>\n",
       "      <td>z***z</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001318</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001242</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Record_ID  Auction_ID Bidder_ID  Bidder_Tendency  Bidding_Ratio  \\\n",
       "0          1         732     _***i         0.200000       0.400000   \n",
       "1          2         732     g***r         0.024390       0.200000   \n",
       "2          3         732     t***p         0.142857       0.200000   \n",
       "3          4         732     7***n         0.100000       0.200000   \n",
       "4          5         900     z***z         0.051282       0.222222   \n",
       "\n",
       "   Successive_Outbidding  Last_Bidding  Auction_Bids  Starting_Price_Average  \\\n",
       "0                    0.0      0.000028           0.0                0.993593   \n",
       "1                    0.0      0.013123           0.0                0.993593   \n",
       "2                    0.0      0.003042           0.0                0.993593   \n",
       "3                    0.0      0.097477           0.0                0.993593   \n",
       "4                    0.0      0.001318           0.0                0.000000   \n",
       "\n",
       "   Early_Bidding  Winning_Ratio  Auction_Duration  Class  \n",
       "0       0.000028       0.666667                 5      0  \n",
       "1       0.013123       0.944444                 5      0  \n",
       "2       0.003042       1.000000                 5      0  \n",
       "3       0.097477       1.000000                 5      0  \n",
       "4       0.001242       0.500000                 7      0  "
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shill = pd.read_csv('Shill_Bidding_Dataset.csv')\n",
    "shill.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bidder_Tendency</th>\n",
       "      <th>Bidding_Ratio</th>\n",
       "      <th>Successive_Outbidding</th>\n",
       "      <th>Last_Bidding</th>\n",
       "      <th>Auction_Bids</th>\n",
       "      <th>Starting_Price_Average</th>\n",
       "      <th>Early_Bidding</th>\n",
       "      <th>Winning_Ratio</th>\n",
       "      <th>Auction_Duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.993593</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013123</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.993593</td>\n",
       "      <td>0.013123</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003042</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.993593</td>\n",
       "      <td>0.003042</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.097477</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.993593</td>\n",
       "      <td>0.097477</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.051282</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001318</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001242</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6316</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.738557</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.993593</td>\n",
       "      <td>0.686358</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6317</th>\n",
       "      <td>0.030612</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005754</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.993593</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6318</th>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015663</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.993593</td>\n",
       "      <td>0.015663</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6319</th>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.068694</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.993593</td>\n",
       "      <td>0.000415</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6320</th>\n",
       "      <td>0.016393</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.340351</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.993593</td>\n",
       "      <td>0.340351</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6321 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Bidder_Tendency  Bidding_Ratio  Successive_Outbidding  Last_Bidding  \\\n",
       "0            0.200000       0.400000                    0.0      0.000028   \n",
       "1            0.024390       0.200000                    0.0      0.013123   \n",
       "2            0.142857       0.200000                    0.0      0.003042   \n",
       "3            0.100000       0.200000                    0.0      0.097477   \n",
       "4            0.051282       0.222222                    0.0      0.001318   \n",
       "...               ...            ...                    ...           ...   \n",
       "6316         0.333333       0.160000                    1.0      0.738557   \n",
       "6317         0.030612       0.130435                    0.0      0.005754   \n",
       "6318         0.055556       0.043478                    0.0      0.015663   \n",
       "6319         0.076923       0.086957                    0.0      0.068694   \n",
       "6320         0.016393       0.043478                    0.0      0.340351   \n",
       "\n",
       "      Auction_Bids  Starting_Price_Average  Early_Bidding  Winning_Ratio  \\\n",
       "0         0.000000                0.993593       0.000028       0.666667   \n",
       "1         0.000000                0.993593       0.013123       0.944444   \n",
       "2         0.000000                0.993593       0.003042       1.000000   \n",
       "3         0.000000                0.993593       0.097477       1.000000   \n",
       "4         0.000000                0.000000       0.001242       0.500000   \n",
       "...            ...                     ...            ...            ...   \n",
       "6316      0.280000                0.993593       0.686358       0.888889   \n",
       "6317      0.217391                0.993593       0.000010       0.878788   \n",
       "6318      0.217391                0.993593       0.015663       0.000000   \n",
       "6319      0.217391                0.993593       0.000415       0.000000   \n",
       "6320      0.217391                0.993593       0.340351       0.000000   \n",
       "\n",
       "      Auction_Duration  \n",
       "0                    5  \n",
       "1                    5  \n",
       "2                    5  \n",
       "3                    5  \n",
       "4                    7  \n",
       "...                ...  \n",
       "6316                 3  \n",
       "6317                 7  \n",
       "6318                 7  \n",
       "6319                 7  \n",
       "6320                 7  \n",
       "\n",
       "[6321 rows x 9 columns]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = shill.drop(columns=['Class', 'Record_ID', 'Auction_ID', 'Bidder_ID'])\n",
    "y = shill.Class\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5646\n",
       "1     675\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 4044\n",
      "Validation set: 1012\n",
      "Test set: 1265\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, stratify = y, random_state = seed)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.2, stratify = y_train, random_state = seed)\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]}\")\n",
    "print(f\"Validation set: {X_val.shape[0]}\")\n",
    "print(f\"Test set: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class balance by Undersampling\n",
    "\n",
    "When undersampling, we aim to remove a number of the rows of the majority class (rows where class=0) in order to match the number of rows of the minority class (rows where class=1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3612\n",
       "1     432\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler(random_state=seed)\n",
    "X_train_us, y_train_us = rus.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    432\n",
       "0    432\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_us.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_us, X_val_us, y_train_us, y_val_us = train_test_split(X_train_us, y_train_us, test_size=0.2, random_state = seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class balance by oversampling with SMOTE\n",
    "\n",
    "Now, oversampling will be performed on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3612\n",
       "1     432\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3612\n",
       "0    3612\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smote = SMOTE(random_state=seed)\n",
    "\n",
    "X_train_os, y_train_os = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "y_train_os.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_os, X_val_os, y_train_os, y_val_os = train_test_split(X_train_os, y_train_os, stratify=y_train_os, test_size=0.2, random_state = seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid Sampling Method\n",
    "\n",
    "A combination of under- and oversampling method using pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 675, 1: 675})\n"
     ]
    }
   ],
   "source": [
    "# define pipeline\n",
    "over = SMOTE(sampling_strategy = \"not minority\")\n",
    "under = RandomUnderSampler(sampling_strategy = \"majority\")\n",
    "steps = [('o', over), ('u', under)]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "\n",
    "# transform the dataset\n",
    "X_h, y_h = pipeline.fit_resample(X, y)\n",
    "# summarize the new class distribution\n",
    "counter = Counter(y_h)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 864\n",
      "Validation set: 216\n",
      "Test set: 270\n"
     ]
    }
   ],
   "source": [
    "X_train_h, X_test_h, y_train_h, y_test_h = train_test_split(X_h, y_h, test_size=0.2, stratify = y_h, random_state=seed)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_h = scaler.fit_transform(X_train_h)\n",
    "X_test_h = scaler.transform(X_test_h)\n",
    "\n",
    "X_train_h, X_val_h, y_train_h, y_val_h = train_test_split(X_train_h, y_train_h, test_size=0.2, stratify=y_train_h, random_state=seed)\n",
    "\n",
    "print(f\"Training set: {X_train_h.shape[0]}\")\n",
    "print(f\"Validation set: {X_val_h.shape[0]}\")\n",
    "print(f\"Test set: {X_test_h.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying Ensemble Learning Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensemble Algorithms\n",
    "\n",
    "    1. Bagged Decision Trees\n",
    "    2. Extra Trees\n",
    "    3. Stochastic Gradient Boosting\n",
    "    4. AdaBoost\n",
    "    5. XGBoost\n",
    "    6. Gradient Boosting\n",
    "    \n",
    "Hyperparameter Tuning\n",
    "After spot-checking machine learning algorithms and imbalanced algorithms, you will have some idea of what works and what does not on your specific dataset.\n",
    "\n",
    "The simplest approach to hyperparameter tuning is to select the top five or 10 algorithms or algorithm combinations that performed well and tune the hyperparameters for each.\n",
    "\n",
    "There are three popular hyperparameter tuning algorithms that you may choose from:\n",
    "\n",
    "    Random Search\n",
    "    Grid Search\n",
    "    Bayesian Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagged Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time 1.389901\n",
      "score_time 0.052299\n",
      "test_accuracy 0.997628\n",
      "test_precision 0.992358\n",
      "test_recall 0.985921\n",
      "test_f1 0.989020\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits = 10, random_state = seed)\n",
    "cart = DecisionTreeClassifier()\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=42)\n",
    "bclf = BaggingClassifier(base_estimator = cart, n_estimators = 200, random_state = seed)\n",
    "\n",
    "scoring = ['accuracy', 'precision', 'recall', 'f1']\n",
    "\n",
    "results = model_selection.cross_validate(bclf, X_scaled, y, cv = kfold, scoring = scoring)\n",
    "\n",
    "for name in results.keys():\n",
    "     print('{} {:.6f}'.format(name, np.average(results[name])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "bclf = BaggingClassifier(base_estimator = cart, n_estimators = tree_no, random_state = seed).fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No   0.998232  0.999115  0.998673      1130\n",
      "         Yes   0.992537  0.985185  0.988848       135\n",
      "\n",
      "    accuracy                       0.997628      1265\n",
      "   macro avg   0.995384  0.992150  0.993760      1265\n",
      "weighted avg   0.997624  0.997628  0.997625      1265\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = bclf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names = ['No','Yes'], digits = 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undersampled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "bclf = BaggingClassifier(base_estimator = cart, n_estimators = tree_no, random_state = seed).fit(X_train_us, y_train_us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time 1.566698\n",
      "score_time 0.062501\n",
      "test_accuracy 0.997628\n",
      "test_precision 0.992358\n",
      "test_recall 0.985921\n",
      "test_f1 0.989020\n"
     ]
    }
   ],
   "source": [
    "scoring = ['accuracy', 'precision', 'recall', 'f1']\n",
    "results = model_selection.cross_validate(bclf, X_scaled, y, cv=kfold, scoring = scoring)\n",
    "\n",
    "for name in results.keys():\n",
    "     print('{} {:.6f}'.format(name, np.average(results[name])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No   1.000000  0.976991  0.988362      1130\n",
      "         Yes   0.838509  1.000000  0.912162       135\n",
      "\n",
      "    accuracy                       0.979447      1265\n",
      "   macro avg   0.919255  0.988496  0.950262      1265\n",
      "weighted avg   0.982766  0.979447  0.980230      1265\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = bclf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names = ['No','Yes'], digits = 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversampled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "bclf = BaggingClassifier(base_estimator = cart, n_estimators = tree_no, random_state = seed).fit(X_train_os, y_train_os)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time 1.629899\n",
      "score_time 0.061400\n",
      "test_accuracy 0.997628\n",
      "test_precision 0.992358\n",
      "test_recall 0.985921\n",
      "test_f1 0.989020\n"
     ]
    }
   ],
   "source": [
    "scoring = ['accuracy', 'precision', 'recall', 'f1']\n",
    "results = model_selection.cross_validate(bclf, X_scaled, y, cv=kfold, scoring = scoring)\n",
    "\n",
    "for name in results.keys():\n",
    "     print('{} {:.6f}'.format(name, np.average(results[name])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No   0.996473  1.000000  0.998233      1130\n",
      "         Yes   1.000000  0.970370  0.984962       135\n",
      "\n",
      "    accuracy                       0.996838      1265\n",
      "   macro avg   0.998236  0.985185  0.991598      1265\n",
      "weighted avg   0.996849  0.996838  0.996817      1265\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = bclf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names = ['No','Yes'], digits = 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hybrid Sampled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "bclf = BaggingClassifier(base_estimator = cart, n_estimators = tree_no, random_state = seed).fit(X_train_h, y_train_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No   1.000000  0.485841  0.653961      1130\n",
      "         Yes   0.188547  1.000000  0.317274       135\n",
      "\n",
      "    accuracy                       0.540711      1265\n",
      "   macro avg   0.594274  0.742920  0.485617      1265\n",
      "weighted avg   0.913402  0.540711  0.618030      1265\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = bclf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names = ['No','Yes'], digits = 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Trees Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imbalanced Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "xtclf = ExtraTreesClassifier(n_estimators = 150, max_features = 5).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No   0.998232  0.999115  0.998673      1130\n",
      "         Yes   0.992537  0.985185  0.988848       135\n",
      "\n",
      "    accuracy                       0.997628      1265\n",
      "   macro avg   0.995384  0.992150  0.993760      1265\n",
      "weighted avg   0.997624  0.997628  0.997625      1265\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = xtclf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names = ['No','Yes'], digits = 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time 0.436200\n",
      "score_time 0.029200\n",
      "test_accuracy 0.997627\n",
      "test_precision 0.989382\n",
      "test_recall 0.988100\n",
      "test_f1 0.988714\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits = 10, random_state = seed)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=42)\n",
    "xtclf = ExtraTreesClassifier(n_estimators = 150, max_features = 5)\n",
    "\n",
    "scoring = ['accuracy', 'precision', 'recall', 'f1']\n",
    "\n",
    "results = model_selection.cross_validate(xtclf, X_scaled, y, cv = kfold, scoring = scoring)\n",
    "\n",
    "for name in results.keys():\n",
    "     print('{} {:.6f}'.format(name, np.average(results[name])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undersampled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No   1.000000  0.980531  0.990170      1130\n",
      "         Yes   0.859873  1.000000  0.924658       135\n",
      "\n",
      "    accuracy                       0.982609      1265\n",
      "   macro avg   0.929936  0.990265  0.957414      1265\n",
      "weighted avg   0.985046  0.982609  0.983178      1265\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xtclf = ExtraTreesClassifier(n_estimators = 150, max_features = 5).fit(X_train_us, y_train_us)\n",
    "y_pred = xtclf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names = ['No','Yes'], digits = 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversampled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No   0.999113  0.997345  0.998229      1130\n",
      "         Yes   0.978102  0.992593  0.985294       135\n",
      "\n",
      "    accuracy                       0.996838      1265\n",
      "   macro avg   0.988608  0.994969  0.991761      1265\n",
      "weighted avg   0.996871  0.996838  0.996848      1265\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xtclf = ExtraTreesClassifier(n_estimators = 150, max_features = 5).fit(X_train_os, y_train_os)\n",
    "y_pred = xtclf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names = ['No','Yes'], digits = 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hybrid Sampled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No   1.000000  0.896460  0.945404      1130\n",
      "         Yes   0.535714  1.000000  0.697674       135\n",
      "\n",
      "    accuracy                       0.907510      1265\n",
      "   macro avg   0.767857  0.948230  0.821539      1265\n",
      "weighted avg   0.950452  0.907510  0.918966      1265\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xtclf = ExtraTreesClassifier(n_estimators = 150, max_features = 5).fit(X_train_h, y_train_h)\n",
    "y_pred = xtclf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names = ['No','Yes'], digits = 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imbalanced Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time 0.410501\n",
      "score_time 0.005999\n",
      "test_accuracy 0.996520\n",
      "test_precision 0.983812\n",
      "test_recall 0.984454\n",
      "test_f1 0.984008\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "kfold = KFold(n_splits = 10, random_state = seed)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=42)\n",
    "\n",
    "gbclf = GradientBoostingClassifier(n_estimators = 50, random_state=seed)\n",
    "\n",
    "scoring = ['accuracy', 'precision', 'recall', 'f1']\n",
    "\n",
    "results = model_selection.cross_validate(gbclf, X_scaled, y, cv = kfold, scoring = scoring)\n",
    "\n",
    "for name in results.keys():\n",
    "     print('{} {:.6f}'.format(name, np.average(results[name])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No   0.998229  0.997345  0.997787      1130\n",
      "         Yes   0.977941  0.985185  0.981550       135\n",
      "\n",
      "    accuracy                       0.996047      1265\n",
      "   macro avg   0.988085  0.991265  0.989668      1265\n",
      "weighted avg   0.996063  0.996047  0.996054      1265\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gbclf = GradientBoostingClassifier(n_estimators = 50, random_state=seed).fit(X_train, y_train)\n",
    "\n",
    "y_pred = gbclf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names = ['No','Yes'], digits = 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undersampled Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No   0.999094  0.976106  0.987466      1130\n",
      "         Yes   0.832298  0.992593  0.905405       135\n",
      "\n",
      "    accuracy                       0.977866      1265\n",
      "   macro avg   0.915696  0.984349  0.946436      1265\n",
      "weighted avg   0.981294  0.977866  0.978709      1265\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gbclf = GradientBoostingClassifier(n_estimators = 50, random_state=seed).fit(X_train_us, y_train_us)\n",
    "\n",
    "y_pred = gbclf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names = ['No','Yes'], digits = 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversampled Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No   1.000000  0.991150  0.995556      1130\n",
      "         Yes   0.931034  1.000000  0.964286       135\n",
      "\n",
      "    accuracy                       0.992095      1265\n",
      "   macro avg   0.965517  0.995575  0.979921      1265\n",
      "weighted avg   0.992640  0.992095  0.992218      1265\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gbclf = GradientBoostingClassifier(n_estimators = 50, random_state=seed).fit(X_train_os, y_train_os)\n",
    "\n",
    "y_pred = gbclf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names = ['No','Yes'], digits = 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hybrid sampled Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No   1.000000  0.431858  0.603214      1130\n",
      "         Yes   0.173745  1.000000  0.296053       135\n",
      "\n",
      "    accuracy                       0.492490      1265\n",
      "   macro avg   0.586873  0.715929  0.449633      1265\n",
      "weighted avg   0.911823  0.492490  0.570434      1265\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gbclf = GradientBoostingClassifier(n_estimators = 50, random_state=seed).fit(X_train_h, y_train_h)\n",
    "\n",
    "y_pred = gbclf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names = ['No','Yes'], digits = 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imbalanced Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time 0.294702\n",
      "score_time 0.020099\n",
      "test_accuracy 0.994621\n",
      "test_precision 0.969238\n",
      "test_recall 0.979374\n",
      "test_f1 0.974124\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "kfold = KFold(n_splits = 10, random_state = seed)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "kfold = model_selection.KFold(n_splits = 10, random_state = 42)\n",
    "\n",
    "abclf = AdaBoostClassifier(n_estimators = 50, random_state = seed)\n",
    "\n",
    "scoring = ['accuracy', 'precision', 'recall', 'f1']\n",
    "\n",
    "results = model_selection.cross_validate(abclf, X_scaled, y, cv = kfold, scoring = scoring)\n",
    "\n",
    "for name in results.keys():\n",
    "     print('{} {:.6f}'.format(name, np.average(results[name])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No   1.000000  0.995575  0.997783      1130\n",
      "         Yes   0.964286  1.000000  0.981818       135\n",
      "\n",
      "    accuracy                       0.996047      1265\n",
      "   macro avg   0.982143  0.997788  0.989800      1265\n",
      "weighted avg   0.996189  0.996047  0.996079      1265\n",
      "\n"
     ]
    }
   ],
   "source": [
    "abclf = AdaBoostClassifier(n_estimators = 50, random_state=seed).fit(X_train, y_train)\n",
    "\n",
    "y_pred = abclf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names = ['No','Yes'], digits = 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undersampled Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No   0.997300  0.980531  0.988844      1130\n",
      "         Yes   0.857143  0.977778  0.913495       135\n",
      "\n",
      "    accuracy                       0.980237      1265\n",
      "   macro avg   0.927221  0.979154  0.951170      1265\n",
      "weighted avg   0.982342  0.980237  0.980803      1265\n",
      "\n"
     ]
    }
   ],
   "source": [
    "abclf = AdaBoostClassifier(n_estimators = 50, random_state=seed).fit(X_train_us, y_train_us)\n",
    "\n",
    "y_pred = abclf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names = ['No','Yes'], digits = 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversampled Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No   0.999111  0.994690  0.996896      1130\n",
      "         Yes   0.957143  0.992593  0.974545       135\n",
      "\n",
      "    accuracy                       0.994466      1265\n",
      "   macro avg   0.978127  0.993641  0.985721      1265\n",
      "weighted avg   0.994632  0.994466  0.994511      1265\n",
      "\n"
     ]
    }
   ],
   "source": [
    "abclf = AdaBoostClassifier(n_estimators = 50, random_state=seed).fit(X_train_os, y_train_os)\n",
    "\n",
    "y_pred = abclf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names = ['No','Yes'], digits = 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hybrid sampled Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No   1.000000  0.634513  0.776394      1130\n",
      "         Yes   0.246350  1.000000  0.395315       135\n",
      "\n",
      "    accuracy                       0.673518      1265\n",
      "   macro avg   0.623175  0.817257  0.585854      1265\n",
      "weighted avg   0.919571  0.673518  0.735726      1265\n",
      "\n"
     ]
    }
   ],
   "source": [
    "abclf = AdaBoostClassifier(n_estimators = 50, random_state=seed).fit(X_train_h, y_train_h)\n",
    "\n",
    "y_pred = abclf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names = ['No','Yes'], digits = 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imbalanced Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:10:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:10:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:10:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:10:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:10:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:10:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:10:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:10:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:10:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:10:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "fit_time 0.250899\n",
      "score_time 0.016001\n",
      "test_accuracy 0.996994\n",
      "test_precision 0.982427\n",
      "test_recall 0.988100\n",
      "test_f1 0.985143\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "kfold = KFold(n_splits = 10, random_state = seed)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "kfold = model_selection.KFold(n_splits = 10, random_state = 42)\n",
    "\n",
    "xgbclf = XGBClassifier(n_estimators = 50, random_state = seed)\n",
    "\n",
    "scoring = ['accuracy', 'precision', 'recall', 'f1']\n",
    "\n",
    "results = model_selection.cross_validate(xgbclf, X_scaled, y, cv = kfold, scoring = scoring)\n",
    "\n",
    "for name in results.keys():\n",
    "     print('{} {:.6f}'.format(name, np.average(results[name])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:10:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No   0.997343  0.996460  0.996901      1130\n",
      "         Yes   0.970588  0.977778  0.974170       135\n",
      "\n",
      "    accuracy                       0.994466      1265\n",
      "   macro avg   0.983966  0.987119  0.985536      1265\n",
      "weighted avg   0.994488  0.994466  0.994475      1265\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgbclf = XGBClassifier(n_estimators = 50, random_state=seed).fit(X_train, y_train)\n",
    "\n",
    "y_pred = xgbclf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names = ['No','Yes'], digits = 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undersampled Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:10:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No   0.999100  0.982301  0.990629      1130\n",
      "         Yes   0.870130  0.992593  0.927336       135\n",
      "\n",
      "    accuracy                       0.983399      1265\n",
      "   macro avg   0.934615  0.987447  0.958982      1265\n",
      "weighted avg   0.985336  0.983399  0.983875      1265\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgbclf = XGBClassifier(n_estimators = 50, random_state=seed).fit(X_train_us, y_train_us)\n",
    "\n",
    "y_pred = xgbclf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names = ['No','Yes'], digits = 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversampled Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:10:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No   0.997340  0.995575  0.996457      1130\n",
      "         Yes   0.963504  0.977778  0.970588       135\n",
      "\n",
      "    accuracy                       0.993676      1265\n",
      "   macro avg   0.980422  0.986676  0.983523      1265\n",
      "weighted avg   0.993729  0.993676  0.993696      1265\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgbclf = XGBClassifier(n_estimators = 50, random_state=seed).fit(X_train_os, y_train_os)\n",
    "\n",
    "y_pred = xgbclf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names = ['No','Yes'], digits = 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hybrid Sampled Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:10:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No   1.000000  0.401770  0.573232      1130\n",
      "         Yes   0.166461  1.000000  0.285412       135\n",
      "\n",
      "    accuracy                       0.465613      1265\n",
      "   macro avg   0.583231  0.700885  0.429322      1265\n",
      "weighted avg   0.911045  0.465613  0.542516      1265\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgbclf = XGBClassifier(n_estimators = 50, random_state=seed).fit(X_train_h, y_train_h)\n",
    "\n",
    "y_pred = xgbclf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names = ['No','Yes'], digits = 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
